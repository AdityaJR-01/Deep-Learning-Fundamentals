# Deep-Learning-Fundamentals
This repo aims to provide a short overview on Deep Learning, and aims to cover the absolute basics anyone may encounter within this domain.

Module-1
1.	Implementation of a single artificial neuron.
    a. Write a program to simulate a single artificial neuron performing binary classification.
    b.Inputs, weights, bias, and activation function.

2.	Implementation of Single Layer Perceptron (SLP).
    a.Train and test SLP on a linearly separable dataset (e.g., AND/OR gate).

3.	Multi-Layer Perceptron (MLP) for XOR Gate.
    a.Design and train MLP to solve the XOR problem.

4.	Activation Functions.
    a.Implement Sigmoid, ReLU, and Tanh activation functions.
    b.Compare their outputs on a dataset.

5.	Forward and Backpropagation.
    a.Implement forward propagation and backpropagation manually for a 2-layer neural network.
