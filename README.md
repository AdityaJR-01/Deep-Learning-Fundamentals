# Deep-Learning-Fundamentals
This repo aims to provide a short overview on Deep Learning, and aims to cover the absolute basics anyone may encounter within this domain.

Module-1
1.	Experiment 1: Implementation of a single artificial neuron.
o	Write a program to simulate a single artificial neuron performing binary classification.
o	Inputs, weights, bias, and activation function.

2.	Experiment 2: Implementation of Single Layer Perceptron (SLP).
o	Train and test SLP on a linearly separable dataset (e.g., AND/OR gate).

3.	Experiment 3: Multi-Layer Perceptron (MLP) for XOR Gate.
o	Design and train MLP to solve the XOR problem.

4.	Experiment 4: Activation Functions.
o	Implement Sigmoid, ReLU, and Tanh activation functions.
o	Compare their outputs on a dataset.

5.	Experiment 5: Forward and Backpropagation.
o	Implement forward propagation and backpropagation manually for a 2-layer neural network.
